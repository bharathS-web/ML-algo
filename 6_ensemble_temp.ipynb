{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "\n",
    "# Load the Wine Quality dataset\n",
    "wine_quality_url = r'datasets\\wine+quality\\winequality-red.csv'\n",
    "wine_data = pd.read_csv(wine_quality_url, delimiter=';')\n",
    "X_wine = wine_data.drop('quality', axis=1)\n",
    "y_wine = wine_data['quality']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Iris dataset\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(X_iris, y_iris, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the Wine Quality dataset\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(X_wine, y_wine, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models\n",
    "log_clf = LogisticRegression(max_iter=1000)\n",
    "rf_clf = RandomForestClassifier()\n",
    "svm_clf = SVC(probability=True)\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "voting_clf_hard = VotingClassifier(estimators=[('lr', log_clf), ('rf', rf_clf), ('svc', svm_clf)], voting='hard')\n",
    "\n",
    "# Soft Voting Classifier (average probability)\n",
    "voting_clf_soft = VotingClassifier(estimators=[('lr', log_clf), ('rf', rf_clf), ('svc', svm_clf)], voting='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging Classifier using Decision Tree\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier (Hard Voting) Accuracy on Iris: 1.0\n",
      "Voting Classifier (Soft Voting) Accuracy on Iris: 1.0\n",
      "Bagging Classifier Accuracy on Iris: 1.0\n",
      "Gradient Boosting Classifier Accuracy on Iris: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate on Iris dataset\n",
    "voting_clf_hard.fit(X_train_iris, y_train_iris)\n",
    "y_pred_iris = voting_clf_hard.predict(X_test_iris)\n",
    "print(\"Voting Classifier (Hard Voting) Accuracy on Iris:\", accuracy_score(y_test_iris, y_pred_iris))\n",
    "\n",
    "voting_clf_soft.fit(X_train_iris, y_train_iris)\n",
    "y_pred_iris = voting_clf_soft.predict(X_test_iris)\n",
    "print(\"Voting Classifier (Soft Voting) Accuracy on Iris:\", accuracy_score(y_test_iris, y_pred_iris))\n",
    "\n",
    "bag_clf.fit(X_train_iris, y_train_iris)\n",
    "y_pred_iris = bag_clf.predict(X_test_iris)\n",
    "print(\"Bagging Classifier Accuracy on Iris:\", accuracy_score(y_test_iris, y_pred_iris))\n",
    "\n",
    "gb_clf.fit(X_train_iris, y_train_iris)\n",
    "y_pred_iris = gb_clf.predict(X_test_iris)\n",
    "print(\"Gradient Boosting Classifier Accuracy on Iris:\", accuracy_score(y_test_iris, y_pred_iris))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sbhar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier (Hard Voting) Accuracy on Wine: 0.6208333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sbhar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier (Soft Voting) Accuracy on Wine: 0.63125\n",
      "Bagging Classifier Accuracy on Wine: 0.6416666666666667\n",
      "Gradient Boosting Classifier Accuracy on Wine: 0.63125\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate on Wine Quality dataset\n",
    "voting_clf_hard.fit(X_train_wine, y_train_wine)\n",
    "y_pred_wine = voting_clf_hard.predict(X_test_wine)\n",
    "print(\"Voting Classifier (Hard Voting) Accuracy on Wine:\", accuracy_score(y_test_wine, y_pred_wine))\n",
    "\n",
    "voting_clf_soft.fit(X_train_wine, y_train_wine)\n",
    "y_pred_wine = voting_clf_soft.predict(X_test_wine)\n",
    "print(\"Voting Classifier (Soft Voting) Accuracy on Wine:\", accuracy_score(y_test_wine, y_pred_wine))\n",
    "\n",
    "bag_clf.fit(X_train_wine, y_train_wine)\n",
    "y_pred_wine = bag_clf.predict(X_test_wine)\n",
    "print(\"Bagging Classifier Accuracy on Wine:\", accuracy_score(y_test_wine, y_pred_wine))\n",
    "\n",
    "gb_clf.fit(X_train_wine, y_train_wine)\n",
    "y_pred_wine = gb_clf.predict(X_test_wine)\n",
    "print(\"Gradient Boosting Classifier Accuracy on Wine:\", accuracy_score(y_test_wine, y_pred_wine))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results for Iris Dataset:\n",
      "Voting (Hard): 0.9666666666666668\n",
      "Voting (Soft): 0.9666666666666668\n",
      "Bagging: 0.9600000000000002\n",
      "Gradient Boosting: 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation for Iris dataset\n",
    "print(\"Cross-Validation Results for Iris Dataset:\")\n",
    "\n",
    "cv_scores_hard_iris = cross_val_score(voting_clf_hard, X_iris, y_iris, cv=5)\n",
    "print(\"Voting (Hard):\", cv_scores_hard_iris.mean())\n",
    "\n",
    "cv_scores_soft_iris = cross_val_score(voting_clf_soft, X_iris, y_iris, cv=5)\n",
    "print(\"Voting (Soft):\", cv_scores_soft_iris.mean())\n",
    "\n",
    "cv_scores_bag_iris = cross_val_score(bag_clf, X_iris, y_iris, cv=5)\n",
    "print(\"Bagging:\", cv_scores_bag_iris.mean())\n",
    "\n",
    "cv_scores_gb_iris = cross_val_score(gb_clf, X_iris, y_iris, cv=5)\n",
    "print(\"Gradient Boosting:\", cv_scores_gb_iris.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Results for Wine Quality Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sbhar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sbhar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sbhar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sbhar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sbhar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting (Hard): 0.559735501567398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sbhar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sbhar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sbhar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sbhar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\sbhar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting (Soft): 0.5903644200626961\n",
      "Bagging: 0.5634874608150471\n",
      "Gradient Boosting: 0.5647198275862069\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-fold cross-validation for Wine Quality dataset\n",
    "print(\"\\nCross-Validation Results for Wine Quality Dataset:\")\n",
    "\n",
    "cv_scores_hard_wine = cross_val_score(voting_clf_hard, X_wine, y_wine, cv=5)\n",
    "print(\"Voting (Hard):\", cv_scores_hard_wine.mean())\n",
    "\n",
    "cv_scores_soft_wine = cross_val_score(voting_clf_soft, X_wine, y_wine, cv=5)\n",
    "print(\"Voting (Soft):\", cv_scores_soft_wine.mean())\n",
    "\n",
    "cv_scores_bag_wine = cross_val_score(bag_clf, X_wine, y_wine, cv=5)\n",
    "print(\"Bagging:\", cv_scores_bag_wine.mean())\n",
    "\n",
    "cv_scores_gb_wine = cross_val_score(gb_clf, X_wine, y_wine, cv=5)\n",
    "print(\"Gradient Boosting:\", cv_scores_gb_wine.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Quality Dataset:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BaggingClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWine Quality Dataset:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m X_wine, y_wine \u001b[38;5;241m=\u001b[39m load_wine_data()\n\u001b[1;32m---> 64\u001b[0m wine_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_classifiers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_wine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_wine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model, accuracy \u001b[38;5;129;01min\u001b[39;00m wine_accuracies\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 35\u001b[0m, in \u001b[0;36mevaluate_classifiers\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Initializing classifiers\u001b[39;00m\n\u001b[0;32m     31\u001b[0m dt \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     33\u001b[0m voting_clf \u001b[38;5;241m=\u001b[39m VotingClassifier(estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     34\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m, dt),\n\u001b[1;32m---> 35\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbagging\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mBaggingClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m),\n\u001b[0;32m     36\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgb\u001b[39m\u001b[38;5;124m'\u001b[39m, GradientBoostingClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[0;32m     37\u001b[0m ], voting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhard\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m bagging_clf \u001b[38;5;241m=\u001b[39m BaggingClassifier(base_estimator\u001b[38;5;241m=\u001b[39mdt, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     40\u001b[0m gb_clf \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: BaggingClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "import requests\n",
    "\n",
    "# Function to load the Wine Quality dataset\n",
    "def load_wine_data():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "    data = pd.read_csv(url, sep=';')\n",
    "    X = data.drop('quality', axis=1)\n",
    "    y = data['quality']\n",
    "    return X, y\n",
    "\n",
    "# Function to load the Iris dataset\n",
    "def load_iris_data():\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    return X, y\n",
    "\n",
    "# Function to train classifiers and compare their accuracies\n",
    "def evaluate_classifiers(X, y):\n",
    "    # Splitting the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initializing classifiers\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    voting_clf = VotingClassifier(estimators=[\n",
    "        ('dt', dt),\n",
    "        ('bagging', BaggingClassifier(base_estimator=dt, n_estimators=10, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "    ], voting='hard')\n",
    "\n",
    "    bagging_clf = BaggingClassifier(base_estimator=dt, n_estimators=10, random_state=42)\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Fit the classifiers\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "    bagging_clf.fit(X_train, y_train)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and calculate accuracies\n",
    "    models = {\n",
    "        \"Voting Classifier\": voting_clf,\n",
    "        \"Bagging Classifier\": bagging_clf,\n",
    "        \"Gradient Boosting Classifier\": gb_clf\n",
    "    }\n",
    "\n",
    "    accuracies = {}\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies[model_name] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "# Evaluate on Wine Quality Dataset\n",
    "print(\"Wine Quality Dataset:\")\n",
    "X_wine, y_wine = load_wine_data()\n",
    "wine_accuracies = evaluate_classifiers(X_wine, y_wine)\n",
    "for model, accuracy in wine_accuracies.items():\n",
    "    print(f\"{model}: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate on Iris Dataset\n",
    "print(\"\\nIris Dataset:\")\n",
    "X_iris, y_iris = load_iris_data()\n",
    "iris_accuracies = evaluate_classifiers(X_iris, y_iris)\n",
    "for model, accuracy in iris_accuracies.items():\n",
    "    print(f\"{model}: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
